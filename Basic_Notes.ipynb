{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None  # default='warn', Mutes warnings when copying a slice from a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = pd.read_csv(\"Data/microbiome.csv\", step=\",\", index_col=['Patient','Taxon'])\n",
    "\n",
    "pd.read_csv(\"Data/microbiome.csv\", skiprows=[3,4,6]).head()\n",
    "pd.read_csv(\"Data/microbiome.csv\", nrows=4)\n",
    "pd.read_csv(\"Data/microbiome_missing.csv\", na_values=['?', -99999]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"baseball_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = pd.read_excel('Data/microbiome_MID2.xls', sheet_name='Sheet 1', header=None)\n",
    "mb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "mb.to_csv(\"mb.csv\")\n",
    "\n",
    "# Binary\n",
    "baseball.to_pickle(\"baseball_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "You put \"index_col\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv(\"Data/baseball.csv\", index_col='id')\n",
    "baseball.head()\n",
    "baseball.describe()\n",
    "baseball.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look by index\n",
    "They have an order so you can look for ranges of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_newind.loc['wickmbo012007']\n",
    "baseball_newind['womacto01CHN2006':'gonzalu01ARI2006']\n",
    "\n",
    "# Asign a value to all the columns of the rowns within this range\n",
    "baseball_newind['womacto01CHN2006':'gonzalu01ARI2006'] = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_3_population = COUNTRIES[\"population_density\"].sort_values(ascending=False).head(3)\n",
    "\n",
    "HAPPINESS[HAPPINESS.index.isin(lowest_3_population.index)][\"happiness_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_id = baseball.player + baseball.year.astype(str)\n",
    "baseball_newind = baseball.copy()\n",
    "baseball_newind.index = player_id\n",
    "baseball_newind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_newind.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also you can just index by the three columns, like having three primary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_h = baseball.set_index(['year', 'team', 'player'])\n",
    "baseball_h.loc[(2007, 'ATL', 'francju01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add and remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns (instead of just a number you can put a vector)\n",
    "data['year'] = 2013\n",
    "COUNTRIES[\"population_density\"] = COUNTRIES[\"population\"] / COUNTRIES[\"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a columns is axis 1\n",
    "data.drop(\"year\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply filters that are not just =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH LAMBDA\n",
    "data[data[\"value\"].apply(lambda x: x > 1000) & data[\"phylum\"].apply(lambda x: str.endswith(x, \"bacteria\"))]\n",
    "\n",
    "\n",
    "# WITH QUERY\n",
    "baseball_newind.query('ab > 500')\n",
    "\n",
    "# To refer to a local variable use @\n",
    "min_ab = 500\n",
    "baseball_newind.query('ab > @min_ab')\n",
    "\n",
    "# Using loc you can look for several columns of one row \n",
    "baseball_newind.loc['gonzalu01ARI2006', ['h','X2b', 'X3b', 'hr']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use loc or just look for one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr2006 = baseball.loc[baseball.year==2006, 'hr']\n",
    "hr2006.index = baseball.player[baseball.year==2006]\n",
    "\n",
    "hr2007 = baseball.loc[baseball.year==2007, 'hr']\n",
    "hr2007.index = baseball.player[baseball.year==2007]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By position\n",
    "using \"iloc\", like i from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first five rows and the columns 5,6,7\n",
    "baseball_newind.iloc[:5, 5:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_newind.sort_index().head()\n",
    "baseball_newind.sort_index(\"col_name\", ascending=False).head()\n",
    "\n",
    "# Sorting values from HR column\n",
    "baseball.hr.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Calculate **on base percentage** for each player, and return the ordered series of estimates.\n",
    "\n",
    "$$obp = \\frac{h + bb + hbp}{ab + bb + hbp + sf}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball['obp']=baseball.apply(\n",
    "  lambda p: \n",
    "    (p.h+p.bb+p.hbp)/(p.ab+p.bb+p.hbp+p.sf) \n",
    "    if (p.ab+p.bb+p.hbp+p.sf) != 0.0 \n",
    "    else 0.0, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_features.groupby(\"world_region\").head()\n",
    "country_features.groupby(\"world_region\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With more than one columns\n",
    "\n",
    "convert Series to DataFrame: `TWO OPTIONS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_region = country_features.groupby(\"world_region\")[\"happiness_score\"].mean()\n",
    "country_region = country_region.to_frame() # <--\n",
    "country_region[\"n_countries\"] = country_features.groupby(\"world_region\")[\"happiness_score\"].count()\n",
    "\n",
    "country_region = country_region.sort_values(\"happiness_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_by_region = country_features.groupby(\"world_region\")['happiness_score'].agg(['mean','size'])\n",
    "average_by_region.sort_values(\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by default, `merge` performs an **inner join** on the tables, meaning that the merged table represents an intersection of the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge by a column (mmsi)\n",
    "The left_index is to make a Join.\n",
    "This way rows that doesn't have a corresponding row in the other table will be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_merged = pd.merge(vessels, segments, left_index=True, right_on='mmsi')\n",
    "segments_merged = pd.merge(vessels, segments, left_index=True, left_of=\"my_column\", right_on='mmsi')\n",
    "\n",
    "\"\"\" DROP THE DUPLICATED COLUMNS JUST IN CASE \"\"\"\n",
    "country_features.drop(\"country_name\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation\n",
    "\n",
    "A common data manipulation is appending rows or columns to a dataset that already conform to the dimensions of the exsiting rows or colums, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([np.random.random(5), np.random.random(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], axis=0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the index is no longer unique, due to overlap between the two `DataFrames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], axis=0).index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_features[country_features[\"literacy\"] == 100].apply(\n",
    "    lambda x: print(f\"{x[\"world_region\"]:<22} - {x[\"country\"]:<10} ({x[\"happiness_score\"]:.2f})\"),\n",
    "    axis=1 #\"\"\" <- AAAAAAAAAAAAAAA \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in country_features[country_features.literacy==100].iterrows():\n",
    "    print(\"{} - {} ({})\".format(row.world_region, row.country, row.happiness_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[foo.notnull()]\n",
    "foo.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be overridden by passing the `how='all'` argument, which only drops a row when every field is a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this programmatically in Pandas with the `fillna` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria2.fillna(0)\n",
    "data.fillna({'year': 2013, 'treatment':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `fillna` by default returns a new object with the desired filling behavior, rather than changing the `Series` or  `DataFrame` **in place**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['treatment'].fillna(2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling nans with other non nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIES['runtime'] = MOVIES['runtime'].combine_first(MOVIES['runtime_new'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "### Basic things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "\"\"\" V1 \"\"\"\n",
    "plt.plot(depths, acuracy_scores, marker=\"o\")\n",
    "\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Accuracy vs max depth')\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.xlim(depths[0] - 1, depths[-1] + 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\"\"\" V2 \"\"\"\n",
    "plt.plot(models, losses, marker=\"o\", label=\"Loss Curve\")  \n",
    "\n",
    "plt.xlabel('Model after x epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.ylim(min(losses) - 0.1, max(losses) + 0.1)  \n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legend plot: `Label=\"...\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_train, train_acc_history, label=\"Train\")\n",
    "plt.plot(t_val, val_acc_history, label=\"Val\")\n",
    "...   \n",
    "plt.legend()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball.plot.scatter(x='hr', y='X2b')\n",
    "baseball.plot.scatter(x='ab', y='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram and Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frecuency\n",
    "baseball['ab'].hist() \n",
    "\n",
    "# By another variabble\n",
    "movies_by_genre = movies.groupby(\"Main_Genre\")[\"imdb_rating\"].mean()\n",
    "sns.barplot(x=movies_by_genre.index, y=movies_by_genre.values, palette=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staked barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Actors 0-20', 'Actors 20-30', 'Actors 30-40', 'Actors 40-60', 'Actors 60+']\n",
    "plot_df = pd.DataFrame(columns=column_names)\n",
    "for _, genre in enumerate(NEW_GENRE[\"categories\"]):\n",
    "    filtered_df = MOVIES[MOVIES[\"new_genres\"].apply(lambda x: genre in x)]\n",
    "    plot_df.loc[len(plot_df)] = filtered_df[column_names].mean()\n",
    "    \n",
    "\n",
    "plot_df.plot(kind='bar', stacked=True, figsize=(14, 8))\n",
    "\n",
    "# Ajouter des titres et labels\n",
    "plt.title(\"Répartition des Acteurs par Classe d'Âge pour Chaque Genre de Film\", fontsize=16)\n",
    "plt.xlabel(\"Genre de Film\", fontsize=14)\n",
    "plt.ylabel(\"Nombre d'Acteurs\", fontsize=14)\n",
    "plt.legend(title=\"Tranche d'Âge\", fontsize=12)\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(CLEAN['Age'], CLEAN['Price'], alpha=0.6, edgecolors='k')\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.scatter(CLEAN['Age'], CLEAN['Price'], alpha=0.6, edgecolors='k')\n",
    "plt.title(\"Car Age vs Price\", fontsize=20)\n",
    "plt.xlabel(\"Car Age (years)\", fontsize=13)\n",
    "plt.ylabel(\"Price (CHF)\", fontsize=13)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plt.subplot(nrows, ncolums, actualPoltIndex)\n",
    "- plt.figure(figsize=(wide, height))\n",
    "- plt.tight_layout() -> avoid overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data_gross = movies.pivot_table(index='Main_Genre', columns='studio', values='worldwide_gross', aggfunc='mean')\n",
    "heatmap_data_rating = movies.pivot_table(index='Main_Genre', columns='studio', values='imdb_rating', aggfunc='mean')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(heatmap_data_gross, cmap='YlGnBu')\n",
    "plt.title(\"Heat map of Genre x Studio by gross\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(heatmap_data_rating, cmap='YlGnBu')\n",
    "plt.title(\"Heat map of Genre x Studio by rating\")\n",
    "\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn\n",
    "### Cool plottings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=movies['worldwide_gross'], y=movies['imdb_rating'], kind=\"hex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat map\n",
    "First create a pivot table (rows x columns each with a value) and the plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = movies.pivot_table(index='Main_Genre', columns='studio', values='worldwide_gross', aggfunc='mean') #mean sum median...\n",
    "\n",
    "sns.heatmap(heatmap_data, cmap='YlGnBu') #cmap = color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(mean_movie_gross_year.index, mean_movie_gross_year)\n",
    "\n",
    "plt.title('Mean Worldwide Gross per Year with Error Bounds')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Worldwide Gross ($)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
