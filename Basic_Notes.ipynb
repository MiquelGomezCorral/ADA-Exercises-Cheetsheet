{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None  # default='warn', Mutes warnings when copying a slice from a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = pd.read_csv(\"Data/microbiome.csv\", step=\",\", index_col=['Patient','Taxon'])\n",
    "\n",
    "pd.read_csv(\"Data/microbiome.csv\", skiprows=[3,4,6]).head()\n",
    "pd.read_csv(\"Data/microbiome.csv\", nrows=4)\n",
    "pd.read_csv(\"Data/microbiome_missing.csv\", na_values=['?', -99999]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"baseball_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = pd.read_excel('Data/microbiome_MID2.xls', sheet_name='Sheet 1', header=None)\n",
    "mb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "mb.to_csv(\"mb.csv\")\n",
    "\n",
    "# Binary\n",
    "baseball.to_pickle(\"baseball_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "You put \"index_col\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv(\"Data/baseball.csv\", index_col='id')\n",
    "baseball.head()\n",
    "baseball.describe()\n",
    "baseball.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look by index\n",
    "They have an order so you can look for ranges of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_newind.loc['wickmbo012007']\n",
    "baseball_newind['womacto01CHN2006':'gonzalu01ARI2006']\n",
    "\n",
    "# Asign a value to all the columns of the rowns within this range\n",
    "baseball_newind['womacto01CHN2006':'gonzalu01ARI2006'] = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_3_population = COUNTRIES[\"population_density\"].sort_values(ascending=False).head(3)\n",
    "\n",
    "HAPPINESS[HAPPINESS.index.isin(lowest_3_population.index)][\"happiness_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_id = baseball.player + baseball.year.astype(str)\n",
    "baseball_newind = baseball.copy()\n",
    "baseball_newind.index = player_id\n",
    "baseball_newind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_newind.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also you can just index by the three columns, like having three primary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_h = baseball.set_index(['year', 'team', 'player'])\n",
    "baseball_h.loc[(2007, 'ATL', 'francju01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add and remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns (instead of just a number you can put a vector)\n",
    "data['year'] = 2013\n",
    "COUNTRIES[\"population_density\"] = COUNTRIES[\"population\"] / COUNTRIES[\"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a columns is axis 1\n",
    "data.drop(\"year\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply filters that are not just =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH LAMBDA\n",
    "data[data[\"value\"].apply(lambda x: x > 1000) & data[\"phylum\"].apply(lambda x: str.endswith(x, \"bacteria\"))]\n",
    "\n",
    "\n",
    "# WITH QUERY\n",
    "baseball_newind.query('ab > 500')\n",
    "\n",
    "# To refer to a local variable use @\n",
    "min_ab = 500\n",
    "baseball_newind.query('ab > @min_ab')\n",
    "\n",
    "# Using loc you can look for several columns of one row \n",
    "baseball_newind.loc['gonzalu01ARI2006', ['h','X2b', 'X3b', 'hr']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use loc or just look for one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr2006 = baseball.loc[baseball.year==2006, 'hr']\n",
    "hr2006.index = baseball.player[baseball.year==2006]\n",
    "\n",
    "hr2007 = baseball.loc[baseball.year==2007, 'hr']\n",
    "hr2007.index = baseball.player[baseball.year==2007]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By position\n",
    "using \"iloc\", like i from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first five rows and the columns 5,6,7\n",
    "baseball_newind.iloc[:5, 5:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_newind.sort_index().head()\n",
    "baseball_newind.sort_index(\"col_name\", ascending=False).head()\n",
    "\n",
    "# Sorting values from HR column\n",
    "baseball.hr.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Calculate **on base percentage** for each player, and return the ordered series of estimates.\n",
    "\n",
    "$$obp = \\frac{h + bb + hbp}{ab + bb + hbp + sf}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball['obp']=baseball.apply(\n",
    "  lambda p: \n",
    "    (p.h+p.bb+p.hbp)/(p.ab+p.bb+p.hbp+p.sf) \n",
    "    if (p.ab+p.bb+p.hbp+p.sf) != 0.0 \n",
    "    else 0.0, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_features.groupby(\"world_region\").head()\n",
    "country_features.groupby(\"world_region\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With more than one columns\n",
    "\n",
    "convert Series to DataFrame: `TWO OPTIONS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_region = country_features.groupby(\"world_region\")[\"happiness_score\"].mean()\n",
    "country_region = country_region.to_frame() # <--\n",
    "country_region[\"n_countries\"] = country_features.groupby(\"world_region\")[\"happiness_score\"].count()\n",
    "\n",
    "country_region = country_region.sort_values(\"happiness_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_by_region = country_features.groupby(\"world_region\")['happiness_score'].agg(['mean','size'])\n",
    "average_by_region.sort_values(\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by default, `merge` performs an **inner join** on the tables, meaning that the merged table represents an intersection of the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge by a column (mmsi)\n",
    "The left_index is to make a Join.\n",
    "This way rows that doesn't have a corresponding row in the other table will be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_merged = pd.merge(vessels, segments, left_index=True, right_on='mmsi')\n",
    "segments_merged = pd.merge(vessels, segments, left_index=True, left_of=\"my_column\", right_on='mmsi')\n",
    "\n",
    "\"\"\" DROP THE DUPLICATED COLUMNS JUST IN CASE \"\"\"\n",
    "country_features.drop(\"country_name\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation\n",
    "\n",
    "A common data manipulation is appending rows or columns to a dataset that already conform to the dimensions of the exsiting rows or colums, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([np.random.random(5), np.random.random(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], axis=0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the index is no longer unique, due to overlap between the two `DataFrames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([mb1, mb2], axis=0).index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_features[country_features[\"literacy\"] == 100].apply(\n",
    "    lambda x: print(f\"{x[\"world_region\"]:<22} - {x[\"country\"]:<10} ({x[\"happiness_score\"]:.2f})\"),\n",
    "    axis=1 #\"\"\" <- AAAAAAAAAAAAAAA \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in country_features[country_features.literacy==100].iterrows():\n",
    "    print(\"{} - {} ({})\".format(row.world_region, row.country, row.happiness_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[foo.notnull()]\n",
    "foo.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be overridden by passing the `how='all'` argument, which only drops a row when every field is a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this programmatically in Pandas with the `fillna` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria2.fillna(0)\n",
    "data.fillna({'year': 2013, 'treatment':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `fillna` by default returns a new object with the desired filling behavior, rather than changing the `Series` or  `DataFrame` **in place**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['treatment'].fillna(2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling nans with other non nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIES['runtime'] = MOVIES['runtime'].combine_first(MOVIES['runtime_new'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
